<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qi-ming-Zhang</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-04-21T04:57:55.205Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Qi-ming-Zhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>OSS第一次作业总结报告</title>
    <link href="http://example.com/2024/04/20/blog%20homework/"/>
    <id>http://example.com/2024/04/20/blog%20homework/</id>
    <published>2024-04-20T12:30:00.000Z</published>
    <updated>2024-04-21T04:57:55.205Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hexo-GitHub-Pages-个人博客部署工作报告"><a href="#Hexo-GitHub-Pages-个人博客部署工作报告" class="headerlink" title="Hexo + GitHub Pages 个人博客部署工作报告"></a>Hexo + GitHub Pages 个人博客部署工作报告</h1><h3 id="I-前言"><a href="#I-前言" class="headerlink" title="I. 前言"></a>I. 前言</h3><p>本报告概述了使用 Hexo 静态网站生成器和 GitHub Pages 服务部署个人博客的过程。本次部署的目的是通过简化的步骤创建和上线一个轻量级、易于维护的个人技术博客。</p><h3 id="II-技术选型"><a href="#II-技术选型" class="headerlink" title="II. 技术选型"></a>II. 技术选型</h3><ol><li><strong>Hexo：</strong> 一个快速、简洁且高效的博客框架，使用 Node.js 编写，适合用于快速构建静态网站。</li><li><strong>GitHub Pages：</strong> 免费托管服务，可直接从 GitHub 仓库部署网页，适用于个人、项目或组织页面。</li></ol><h3 id="III-实施步骤"><a href="#III-实施步骤" class="headerlink" title="III. 实施步骤"></a>III. 实施步骤</h3><h4 id="步骤-1-环境准备"><a href="#步骤-1-环境准备" class="headerlink" title="步骤 1: 环境准备"></a>步骤 1: 环境准备</h4><ol><li><p><strong>安装 Node.js</strong><br>确认 Node.js 已正确安装，使用命令 <code>node -v</code> 和 <code>npm -v</code> 检查版本。</p></li><li><p><strong>安装 Git</strong><br>用于版本控制和推送代码到 GitHub。安装后通过 <code>git --version</code> 验证。</p></li></ol><h4 id="步骤-2-安装-Hexo"><a href="#步骤-2-安装-Hexo" class="headerlink" title="步骤 2: 安装 Hexo"></a>步骤 2: 安装 Hexo</h4><ol><li><p><strong>全局安装 Hexo CLI</strong><br>执行命令 <code>npm install -g hexo-cli</code>。</p></li><li><p><strong>创建 Hexo 项目</strong><br>终端运行 <code>hexo init blog</code> 创建名为 ‘blog’ 的新目录，并初始化博客项目。</p></li><li><p><strong>安装依赖</strong><br>进入 ‘blog’ 目录，执行 <code>npm install</code> 安装所需依赖。</p></li></ol><h4 id="步骤-2-下载主题"><a href="#步骤-2-下载主题" class="headerlink" title="步骤 2: 下载主题"></a>步骤 2: 下载主题</h4><ol><li><p><strong>下载主题模板</strong> </p><p> <code>git clone</code> 相关主题模板，放置在<code>themes</code>下。</p></li><li><p><strong>修改主题配置</strong> </p><p>进入 <code>_config.yml</code>，对应修改<code>themes</code> 配置。</p></li></ol><h4 id="步骤-4-配置博客"><a href="#步骤-4-配置博客" class="headerlink" title="步骤 4: 配置博客"></a>步骤 4: 配置博客</h4><ol><li><p><strong>编辑 <code>_config.yml</code></strong><br>修改网站标题、作者等配置信息，适应个人需求。</p></li><li><p><strong>新建文章</strong><br>使用 <code>hexo new &quot;我的第一篇博客&quot;</code> 创建新文章。</p></li></ol><h4 id="步骤-5-本地预览和调试"><a href="#步骤-5-本地预览和调试" class="headerlink" title="步骤 5: 本地预览和调试"></a>步骤 5: 本地预览和调试</h4><ol><li><strong>启动本地服务器</strong><br>执行 <code>hexo server</code>，通过 <code>http://localhost:4000</code> 预览博客。</li></ol><h4 id="步骤-6-部署到-GitHub"><a href="#步骤-6-部署到-GitHub" class="headerlink" title="步骤 6: 部署到 GitHub"></a>步骤 6: 部署到 GitHub</h4><ol><li><p><strong>配置部署</strong><br>在 <code>_config.yml</code> 中设置 <code>deploy</code> 部分，选择 GitHub Pages 作为部署平台。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">&lt;GitHub仓库URL&gt;</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure></li><li><p><strong>安装 Hexo 部署插件</strong><br>执行命令 <code>npm install hexo-deployer-git --save</code>。</p></li><li><p><strong>一键部署命令</strong><br>执行 <code>hexo clean &amp;&amp; hexo deploy</code>，清理缓存并推送至 GitHub。</p></li></ol><h3 id="IV-结果与展示"><a href="#IV-结果与展示" class="headerlink" title="IV. 结果与展示"></a>IV. 结果与展示</h3><p>​部署完成后，博客成功托管在 GitHub Pages 上。通过直接访问 <code>&lt;username&gt;.github.io</code> 可以看到上线的博客页面，样式简洁，加载速度快。</p><h3 id="V-后续维护与计划"><a href="#V-后续维护与计划" class="headerlink" title="V. 后续维护与计划"></a>V. 后续维护与计划</h3><ul><li><strong>内容更新：</strong> 定期通过 Hexo 写新文章并部署更新。</li><li><strong>主题优化：</strong> 根据需要调整或更换 Hexo 主题以增强博客的视觉吸引力。</li><li><strong>功能扩展：</strong> 可考虑添加评论系统、搜索功能等。</li></ul><h3 id="VI-结论"><a href="#VI-结论" class="headerlink" title="VI. 结论"></a>VI. 结论</h3><p>​使用 Hexo 结合 GitHub Pages 部署个人博客是一个高效且成本低的选择，适合个人技术展示和内容分享。整个部署过程简单明了，易于操作，也易于维护更新。通过本次成功的部署，提升了个人在网站开发和维护的实践经验。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Hexo-GitHub-Pages-个人博客部署工作报告&quot;&gt;&lt;a href=&quot;#Hexo-GitHub-Pages-个人博客部署工作报告&quot; class=&quot;headerlink&quot; title=&quot;Hexo + GitHub Pages 个人博客部署工作报告&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="Homework" scheme="http://example.com/categories/Homework/"/>
    
    
    <category term="Hexo" scheme="http://example.com/tags/Hexo/"/>
    
    <category term="GitHub Pages" scheme="http://example.com/tags/GitHub-Pages/"/>
    
  </entry>
  
  <entry>
    <title>BigdL的GPU加速</title>
    <link href="http://example.com/2024/03/30/bigdl2/"/>
    <id>http://example.com/2024/03/30/bigdl2/</id>
    <published>2024-03-30T13:30:00.000Z</published>
    <updated>2024-04-21T04:28:28.695Z</updated>
    
    <content type="html"><![CDATA[<p>IPEX-LLM 借助低精度技术、现代硬件加速和最新的软件优化，支持在英特尔 GPU 上优化任何 <a href="https://huggingface.co/docs/transformers/index"><em>HuggingFace transformers</em></a> 模型。</p><h4 id="在英特尔锐炫-GPU-上运行-6B-模型（实时屏幕画面）"><a href="#在英特尔锐炫-GPU-上运行-6B-模型（实时屏幕画面）" class="headerlink" title="在英特尔锐炫 GPU 上运行 6B 模型（实时屏幕画面）:"></a>在英特尔锐炫 GPU 上运行 6B 模型（实时屏幕画面）:</h4><p align="left">            <img src="https://llm-assets.readthedocs.io/en/latest/_images/chatglm2-arc.gif" width='60%' /> <h4 id="在英特尔锐炫-GPU-上运行-13B-模型（实时屏幕画面）"><a href="#在英特尔锐炫-GPU-上运行-13B-模型（实时屏幕画面）" class="headerlink" title="在英特尔锐炫 GPU 上运行 13B 模型（实时屏幕画面）:"></a>在英特尔锐炫 GPU 上运行 13B 模型（实时屏幕画面）:</h4><p align="left">            <img src="https://llm-assets.readthedocs.io/en/latest/_images/llama2-13b-arc.gif" width='60%' /> <p>在第六章中，您将学习如何在英特尔 GPU 上使用 IPEX-LLM 优化来运行 LLM 以及实现流式对话功能。本章将使用流行的开源模型作为示例：</p><ul><li><a href="./6_1_GPU_Llama2-7B.md">Llama2-7B</a></li></ul><h2 id="0-环境配置"><a href="#0-环境配置" class="headerlink" title="0 环境配置"></a>0 环境配置</h2><p>以下是一些设置环境的最佳做法。强烈建议您按照以下相应步骤正确配置环境。</p><h3 id="0-1-系统需求"><a href="#0-1-系统需求" class="headerlink" title="0.1 系统需求"></a>0.1 系统需求</h3><p>为了顺利体验第六章中的 Notebook，请确保您的硬件和操作系统符合以下要求：</p><blockquote><p>⚠️硬件</p><ul><li>英特尔锐炫™ A系列显卡</li><li>英特尔 Data Center GPU Flex Series</li><li>英特尔 Data Center GPU Max Series</li></ul></blockquote><blockquote><p>⚠️操作系统</p><ul><li>Linux 系统, 推荐使用 Ubuntu 22.04</li></ul></blockquote><pre><code>&gt; **注意**&gt; 请注意，英特尔 GPU 上的 IPEX-LLM 优化仅支持 Linux 操作系统。</code></pre><h3 id="0-2-安装驱动程序和工具包"><a href="#0-2-安装驱动程序和工具包" class="headerlink" title="0.2 安装驱动程序和工具包"></a>0.2 安装驱动程序和工具包</h3><p>在英特尔 GPU 上使用 IPEX-LLM 之前，有几个安装工具的步骤：</p><ul><li><p>首先，您需要安装英特尔 GPU 驱动程序。请参阅我们的<a href="https://dgpu-docs.intel.com/driver/installation.html">驱动程序安装</a>以了解更多关于通用 GPU 功能的事项。</p><blockquote><p><strong>注意</strong><br>对于使用默认 IPEX 版本（IPEX 2.0.110+xpu）的 IPEX-LLM，需要英特尔 GPU 驱动程序版本 <a href="https://dgpu-docs.intel.com/releases/stable_647_21_20230714.html">Stable 647.21</a>。</p></blockquote></li><li><p>您还需要下载并安装<a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html">英特尔® oneAPI Base Toolkit</a>。OneMKL 和 DPC++ 编译器是必选项，其他为可选项。</p><blockquote><p><strong>注意</strong><br>使用默认 IPEX 版本（IPEX 2.0.110+xpu）的 IPEX-LLM 需要英特尔® oneAPI Base Toolkit 的版本 &#x3D;&#x3D; 2023.2.0。</p></blockquote></li></ul><details><summary>对于在 Ubuntu 22.04 上使用英特尔锐炫™ A 系列显卡的客户端用户，也可参考以下命令安装驱动程序和 oneAPI Base Toolkit。详细命令：</summary><br/><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装锐炫驱动程序</span></span><br><span class="line">sudo apt-get install -y gpg-agent wget</span><br><span class="line"></span><br><span class="line">wget -qO - https://repositories.intel.com/graphics/intel-graphics.key | \</span><br><span class="line">  sudo gpg --dearmor --output /usr/share/keyrings/intel-graphics.gpg</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;deb [arch=amd64,i386 signed-by=/usr/share/keyrings/intel-graphics.gpg] https://repositories.intel.com/graphics/ubuntu jammy arc&#x27;</span> | \</span><br><span class="line">  sudo <span class="built_in">tee</span>  /etc/apt/sources.list.d/intel.gpu.jammy.list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 降级内核版本</span></span><br><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install  -y --install-suggests  linux-image-5.19.0-41-generic</span><br><span class="line"></span><br><span class="line">sudo sed -i <span class="string">&quot;s/GRUB_DEFAULT=.*/GRUB_DEFAULT=\&quot;1&gt; <span class="subst">$(echo $(($(awk -F\&#x27; &#x27;/menuentry / &#123;print $2&#125;&#x27; /boot/grub/grub.cfg \</span></span></span><br><span class="line"><span class="subst"><span class="string">| grep -no &#x27;5.19.0-41&#x27; | sed &#x27;s/:/\n/g&#x27; | head -n 1)</span>-2)))\&quot;/&quot;</span> /etc/default/grub</span><br><span class="line"></span><br><span class="line">sudo  update-grub</span><br><span class="line"></span><br><span class="line">sudo reboot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除最新版本内核</span></span><br><span class="line">sudo apt purge linux-image-6.2.0-26-generic</span><br><span class="line"></span><br><span class="line">sudo apt autoremove</span><br><span class="line"></span><br><span class="line">sudo reboot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装驱动程序</span></span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">sudo apt-get -y install \</span><br><span class="line">    gawk \</span><br><span class="line">    dkms \</span><br><span class="line">    linux-headers-$(<span class="built_in">uname</span> -r) \</span><br><span class="line">    libc6-dev</span><br><span class="line"></span><br><span class="line">sudo apt-get install -y intel-platform-vsec-dkms intel-platform-cse-dkms intel-i915-dkms intel-fw-gpu</span><br><span class="line"></span><br><span class="line">sudo apt-get install -y gawk libc6-dev udev\</span><br><span class="line">  intel-opencl-icd intel-level-zero-gpu level-zero \</span><br><span class="line">  intel-media-va-driver-non-free libmfx1 libmfxgen1 libvpl2 \</span><br><span class="line">  libegl-mesa0 libegl1-mesa libegl1-mesa-dev libgbm1 libgl1-mesa-dev libgl1-mesa-dri \</span><br><span class="line">  libglapi-mesa libgles2-mesa-dev libglx-mesa0 libigdgmm12 libxatracker2 mesa-va-drivers \</span><br><span class="line">  mesa-vdpau-drivers mesa-vulkan-drivers va-driver-all vainfo</span><br><span class="line">  </span><br><span class="line">sudo reboot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置权限</span></span><br><span class="line">sudo gpasswd -a <span class="variable">$&#123;USER&#125;</span> render</span><br><span class="line"></span><br><span class="line">newgrp render</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证设备是否可以使用 i915 驱动程序正常运行</span></span><br><span class="line">sudo apt-get install -y hwinfo</span><br><span class="line">hwinfo --display</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 one api</span></span><br><span class="line">wget -O- https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB | gpg --dearmor | sudo <span class="built_in">tee</span> /usr/share/keyrings/oneapi-archive-keyring.gpg &gt; /dev/null</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main&quot;</span> | sudo <span class="built_in">tee</span> /etc/apt/sources.list.d/oneAPI.list</span><br><span class="line"></span><br><span class="line">sudo apt update</span><br><span class="line"></span><br><span class="line">sudo apt install intel-basekit</span><br></pre></td></tr></table></figure><h3 id="0-3-Python-环境配置"><a href="#0-3-Python-环境配置" class="headerlink" title="0.3 Python 环境配置"></a>0.3 Python 环境配置</h3><p>接下来，使用 python 环境管理工具（推荐使用 <a href="https://docs.conda.io/projects/conda/en/stable/">Conda</a>）创建 python 环境并安装必要的库。</p><h4 id="0-3-1-安装-Conda"><a href="#0-3-1-安装-Conda" class="headerlink" title="0.3.1 安装 Conda"></a>0.3.1 安装 Conda</h4><p>对于 Linux 用户，打开终端并运行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">bash ./Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">conda init</span><br></pre></td></tr></table></figure><blockquote><p><strong>注意</strong><br>按照控制台弹出的提示操作，直到 conda 初始化成功完成。</p></blockquote><h4 id="0-3-2-创建环境"><a href="#0-3-2-创建环境" class="headerlink" title="0.3.2 创建环境"></a>0.3.2 创建环境</h4><blockquote><p><strong>注意</strong><br>推荐使用 Python 3.9 运行 IPEX-LLM.</p></blockquote><p>使用您选择的名称创建一个 Python 3.9 环境，例如 <code>llm-tutorial-gpu</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n llm-tutorial-gpu python=3.9</span><br></pre></td></tr></table></figure><p>接下来激活环境 <code>llm-tutorial-gpu</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate llm-tutorial-gpu</span><br></pre></td></tr></table></figure><h3 id="0-4-Linux-上的推荐配置"><a href="#0-4-Linux-上的推荐配置" class="headerlink" title="0.4 Linux 上的推荐配置"></a>0.4 Linux 上的推荐配置</h3><p>为优化英特尔 GPU 的性能，建议设置以下几个环境变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置 OneAPI 环境变量</span></span><br><span class="line"><span class="built_in">source</span> /opt/intel/oneapi/setvars.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> USE_XETLA=OFF</span><br><span class="line"><span class="built_in">export</span> SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS=1</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;IPEX-LLM 借助低精度技术、现代硬件加速和最新的软件优化，支持在英特尔 GPU 上优化任何 &lt;a href=&quot;https://huggingface.co/docs/transformers/index&quot;&gt;&lt;em&gt;HuggingFace transformers&lt;/e</summary>
      
    
    
    
    <category term="BigDL" scheme="http://example.com/categories/BigDL/"/>
    
    
    <category term="BigDL" scheme="http://example.com/tags/BigDL/"/>
    
    <category term="LLM" scheme="http://example.com/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>BigdL的大模型微调</title>
    <link href="http://example.com/2024/03/30/bigdl3/"/>
    <id>http://example.com/2024/03/30/bigdl3/</id>
    <published>2024-03-30T13:30:00.000Z</published>
    <updated>2024-04-21T04:28:20.520Z</updated>
    
    <content type="html"><![CDATA[<p>作为最新的参数微调方法，QLoRA 能够在仅微调少量参数情况下高效地将专业知识注入到预训练后的大语言模型中。IPEX-LLM 同样支持使用QLora 在英特尔 GPU 上进行 4 bit 优化来微调 LLM（大语言模型）。</p><blockquote><p><strong>注意</strong></p><p>目前仅支持Hugging Face Transformers模型运行QLoRA微调，且IPEX-LLM支持在英特尔GPU上优化任何 <a href="https://huggingface.co/docs/transformers/index"><em>HuggingFace Transformers</em></a>模型。<br>目前，IPEX-LLM 仅支持对<a href="https://huggingface.co/docs/transformers/index">Hugging Face <code>transformers</code> 模型</a>进行 QLoRA 微调。</p></blockquote><p>在第7章中，您将了解如何使用 IPEX-LLM 优化将大型语言模型微调适配文本生成任务。IPEX-LLM 可帮助您微调模型、进行 LoRA 权重与基本权重的合并以及应用合并后的模型进行推理。</p><p>我们将以当下流行的开源模型 <a href="https://huggingface.co/meta-llama/Llama-2-7b-hf">Llama-2-7b-hf</a> 为例进行训练。</p><h2 id="0-环境设置"><a href="#0-环境设置" class="headerlink" title="0 环境设置"></a>0 环境设置</h2><p>您可以按照<a href="./ch_6_GPU_Acceleration/README.md">第6章</a> 中的详细说明在英特尔 GPU 上配置环境。以下仅列举正确配置环境的<strong>必要</strong>步骤。</p><h3 id="0-1-系统需求"><a href="#0-1-系统需求" class="headerlink" title="0.1 系统需求"></a>0.1 系统需求</h3><blockquote><p>⚠️硬件</p><ul><li>英特尔 Arc™ A 系列显卡</li><li>英特尔数据中心 GPU Flex 系列</li><li>英特尔数据中心 GPU Max 系列</li></ul></blockquote><blockquote><p>⚠️操作系统</p><ul><li>Linux系统，Ubuntu 22.04优先</li></ul></blockquote><h3 id="0-2-安装驱动程序和工具包"><a href="#0-2-安装驱动程序和工具包" class="headerlink" title="0.2 安装驱动程序和工具包"></a>0.2 安装驱动程序和工具包</h3><p>在英特尔 GPU 上使用 IPEX-LLM 之前，有几个安装工具的步骤：</p><ul><li><p>首先，您需要安装英特尔 GPU 驱动程序。请参阅我们的驱动程序安装以了解更多关于通用 GPU 功能的事项。</p></li><li><p>您还需要下载并安装英特尔® oneAPI Base Toolkit。OneMKL 和 DPC++ 编译器是必选项，其他为可选项。</p></li></ul><h3 id="0-3-Python环境配置"><a href="#0-3-Python环境配置" class="headerlink" title="0.3 Python环境配置"></a>0.3 Python环境配置</h3><p>假设您已经安装了<a href="https://docs.conda.io/projects/conda/en/stable/">Conda</a>作为您的python环境管理工具，下面的命令可以帮助您创建并激活您的 Python 环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建议使用 Python 3.9 来运行 IPEX-LLM</span></span><br><span class="line">conda create -n llm-finetune python=3.9</span><br><span class="line">conda activate llm-finetune </span><br></pre></td></tr></table></figure><h3 id="0-4-设置OneAPI环境变量"><a href="#0-4-设置OneAPI环境变量" class="headerlink" title="0.4 设置OneAPI环境变量"></a>0.4 设置OneAPI环境变量</h3><p>您需要在 Intel GPU 上为 IPEX-LLM 设置 OneAPI 环境变量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置 OneAPI 环境变量</span></span><br><span class="line"><span class="built_in">source</span> /opt/intel/oneapi/setvars.sh</span><br></pre></td></tr></table></figure><h3 id="0-5（可选项）-在英特尔-GPU-上运行模型推理的配置"><a href="#0-5（可选项）-在英特尔-GPU-上运行模型推理的配置" class="headerlink" title="0.5（可选项） 在英特尔 GPU 上运行模型推理的配置"></a>0.5（可选项） 在英特尔 GPU 上运行模型推理的配置</h3><p>如果您想使用英特尔 GPU 对微调后的模型进行推理，建议设置以下变量以达到最佳性能：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> USE_XETLA=OFF</span><br><span class="line"><span class="built_in">export</span> SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS=1</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;作为最新的参数微调方法，QLoRA 能够在仅微调少量参数情况下高效地将专业知识注入到预训练后的大语言模型中。IPEX-LLM 同样支持使用QLora 在英特尔 GPU 上进行 4 bit 优化来微调 LLM（大语言模型）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;stro</summary>
      
    
    
    
    <category term="BigDL" scheme="http://example.com/categories/BigDL/"/>
    
    
    <category term="BigDL" scheme="http://example.com/tags/BigDL/"/>
    
    <category term="LLM" scheme="http://example.com/tags/LLM/"/>
    
    <category term="QLoRA" scheme="http://example.com/tags/QLoRA/"/>
    
  </entry>
  
  <entry>
    <title>BigdL环境部署</title>
    <link href="http://example.com/2024/03/30/bigdl1/"/>
    <id>http://example.com/2024/03/30/bigdl1/</id>
    <published>2024-03-30T12:30:00.000Z</published>
    <updated>2024-04-21T04:27:32.524Z</updated>
    
    <content type="html"><![CDATA[<p>本章介绍BigDL一系列环境配置的最佳实践。为了确保在后续章节中顺利使用 Jupyter Notebook, 强烈建议您按照以下相应步骤正确配置环境。</p><h2 id="1-系统建议"><a href="#1-系统建议" class="headerlink" title="1 系统建议"></a>1 系统建议</h2><p>首先，选择一个合适的系统。以下是推荐的硬件与操作系统列表：</p><blockquote><p>⚠️<strong>硬件</strong></p></blockquote><ul><li>至少 16GB 内存的英特尔®个人电脑</li><li>搭载英特尔®至强®处理器和至少 32GB 内存的服务器</li></ul><blockquote><p>⚠️<strong>操作系统</strong></p></blockquote><ul><li>Ubuntu 20.04 或更高版本</li><li>CentOS 7 或更高版本</li><li>Windows 10&#x2F;11, 有无WSL均可</li></ul><h2 id="2-设置-Python-环境"><a href="#2-设置-Python-环境" class="headerlink" title="2 设置 Python 环境"></a>2 设置 Python 环境</h2><p>接下来，使用 Python 环境管理工具（推荐使用 <a href="https://docs.conda.io/projects/conda/en/stable/">Conda</a> ）创建 Python 环境并安装必要的库。</p><h3 id="2-1-安装-Conda"><a href="#2-1-安装-Conda" class="headerlink" title="2.1 安装 Conda"></a>2.1 安装 Conda</h3><p>请按照下面与您的操作系统相对应的说明进行操作。</p><h4 id="2-1-1-Linux"><a href="#2-1-1-Linux" class="headerlink" title="2.1.1 Linux"></a>2.1.1 Linux</h4><p>对于 Linux 用户，打开终端并且运行以下命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">bash ./Miniconda3-latest-Linux-x86_64.sh</span><br><span class="line">conda init</span><br></pre></td></tr></table></figure><blockquote><p><strong>注意</strong><br>请按照终端显示的说明进行操作，直到 conda 初始化成功完成。</p></blockquote><h4 id="2-1-2-Windows"><a href="#2-1-2-Windows" class="headerlink" title="2.1.2 Windows"></a>2.1.2 Windows</h4><p>对于 Windows 用户，在<a href="https://docs.conda.io/en/latest/miniconda.html#latest-miniconda-installer-links">这里</a>下载 conda 安装包并运行。</p><p>在安装完成后，打开 “Anaconda Powershell Prompt (Miniconda3)” 执行以下步骤。</p><h4 id="2-1-3-适用于-Linux-的-Windows-子系统-WSL"><a href="#2-1-3-适用于-Linux-的-Windows-子系统-WSL" class="headerlink" title="2.1.3 适用于 Linux 的 Windows 子系统 (WSL):"></a>2.1.3 适用于 Linux 的 Windows 子系统 (WSL):</h4><p>对于 WSL 用户，请确保已经安装了 WSL2。如果没有，请参阅<a href="https://bigdl.readthedocs.io/en/latest/doc/UserGuide/win.html#install-wsl2l">此处</a>了解安装方法。</p><p>打开 WSL2 shell 并运行与 <a href="#2211-linux">2.2.1.1 Linux</a> 相同的命令。</p><h3 id="2-2-创建环境"><a href="#2-2-创建环境" class="headerlink" title="2.2 创建环境"></a>2.2 创建环境</h3><blockquote><p><strong>注意</strong><br>推荐使用 Python 3.9 运行 IPEX-LLM.</p></blockquote><p>创建一个 Python 3.9 环境，名称由您选择，例如 <code>llm-tutorial</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n llm-tutorial python=3.9</span><br></pre></td></tr></table></figure><p>然后激活环境 <code>llm-tutorial</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate llm-tutorial</span><br></pre></td></tr></table></figure><h2 id="3-安装-IPEX-LLM"><a href="#3-安装-IPEX-LLM" class="headerlink" title="3 安装 IPEX-LLM"></a>3 安装 IPEX-LLM</h2><p>下面这一行命令将安装最新版本的<code>ipex-llm</code>以及所有常见LLM应用程序开发所需的依赖项。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --pre --upgrade ipex-llm[all]</span><br></pre></td></tr></table></figure><h2 id="4-安装-Jupyter-服务"><a href="#4-安装-Jupyter-服务" class="headerlink" title="4 安装 Jupyter 服务"></a>4 安装 Jupyter 服务</h2><h3 id="4-1-安装-Jupyter"><a href="#4-1-安装-Jupyter" class="headerlink" title="4.1 安装 Jupyter"></a>4.1 安装 Jupyter</h3><p>运行教程提供的 Notebook (即 <code>.ipynb</code> 文件) 需要 <code>jupyter</code> 库。在激活的 Python 3.9 环境下运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install jupyter</span><br></pre></td></tr></table></figure><h3 id="4-2-启动-Jupyter-服务"><a href="#4-2-启动-Jupyter-服务" class="headerlink" title="4.2 启动 Jupyter 服务"></a>4.2 启动 Jupyter 服务</h3><p>启动 jupyter 服务的推荐指令在个人电脑和服务器上略有不同。</p><h4 id="4-2-1-在个人电脑上"><a href="#4-2-1-在个人电脑上" class="headerlink" title="4.2.1 在个人电脑上"></a>4.2.1 在个人电脑上</h4><p>在个人电脑上，只需在 shell 中运行以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure><h4 id="4-2-2-在服务器上"><a href="#4-2-2-在服务器上" class="headerlink" title="4.2.2 在服务器上"></a>4.2.2 在服务器上</h4><p>在服务器上，建议使用单个插槽的所有物理核心以获得更好的性能。因此，请运行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以每个插槽有48个核心的服务器为例</span></span><br><span class="line"><span class="built_in">export</span> OMP_NUM_THREADS=48</span><br><span class="line">numactl -C 0-47 -m 0 jupyter notebook</span><br></pre></td></tr></table></figure><p>祝贺您！现在您可以使用浏览器来访问 jupyter 服务 url 并运行本教程提供的notebooks。</p><h2 id="5-关于使用LLM的一些你可能想要了解的事项"><a href="#5-关于使用LLM的一些你可能想要了解的事项" class="headerlink" title="5 关于使用LLM的一些你可能想要了解的事项"></a>5 关于使用LLM的一些你可能想要了解的事项</h2><p>如果您在LLM和LLM应用程序开发方面是新手，本节可能包含了一些您想要了解的内容。</p><h3 id="5-1-去哪里找模型"><a href="#5-1-去哪里找模型" class="headerlink" title="5.1 去哪里找模型"></a>5.1 去哪里找模型</h3><p>首先，您需要获取一个模型。社区中有许多开源的LLM可供选择。如果您没有特定的目标，可以考虑从社区公开的LLM排行榜上排名较高的模型中选择。这些公开的LLM排行榜一般采用多种评测手段评估和比较多个LLM的能力。一些比较有名的排行榜包括：</p><ul><li><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM LeaderBoard</a> 由 Huggingface 维护 </li><li><a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard">Chatbot Arena Leaderboard</a> 由 llmsys 维护</li></ul><p>这些排行榜大多包含了列出的模型的参考链接。如果一个模型是开源的，您可以直接从提供的链接中轻松下载并尝试使用。</p><h3 id="5-2-从Huggingface下载模型"><a href="#5-2-从Huggingface下载模型" class="headerlink" title="5.2 从Huggingface下载模型"></a>5.2 从Huggingface下载模型</h3><p>截止到目前为止，许多热门的LLM模型都托管在Huggingface上。Huggingface托管的一个示例模型主页如下所示。<br><img src="https://github.com/shane-huang/bigdl-llm-tutorial/assets/1995599/a04df95f-5590-4bf1-968c-32cf494ece92" alt="image"></p><p>要从Huggingface下载模型，您可以使用git或Huggingface提供的API。有关如何下载模型的详细信息，请参阅<a href="https://huggingface.co/docs/hub/models-downloading">从Huggingface下载模型</a> 。</p><p>通常从Huggingface下载的模型可以使用<a href="https://huggingface.co/docs/transformers/index">Huggingface Transformers库</a>加载。IPEX-LLM提供了API，可以轻松地与这些模型一起使用。请阅读本教程后续章节了解更多信息。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本章介绍BigDL一系列环境配置的最佳实践。为了确保在后续章节中顺利使用 Jupyter Notebook, 强烈建议您按照以下相应步骤正确配置环境。&lt;/p&gt;
&lt;h2 id=&quot;1-系统建议&quot;&gt;&lt;a href=&quot;#1-系统建议&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    <category term="BigDL" scheme="http://example.com/categories/BigDL/"/>
    
    
    <category term="BigDL" scheme="http://example.com/tags/BigDL/"/>
    
    <category term="LLM" scheme="http://example.com/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>极狐Runner修复</title>
    <link href="http://example.com/2023/12/30/runner/"/>
    <id>http://example.com/2023/12/30/runner/</id>
    <published>2023-12-30T13:30:00.000Z</published>
    <updated>2024-04-21T04:37:20.359Z</updated>
    
    <content type="html"><![CDATA[<p>首先需要注意使用<strong>docker</strong>方式安装runner而不是服务器方式安装runner，这样不仅安装简单，还有利于后续对runner的配置。</p><h2 id="获取权限"><a href="#获取权限" class="headerlink" title="获取权限"></a>获取权限</h2><p>要注册一个group runner，首先要获取这个runner的Onwer权限，这里就是需要获得CS4ALL这个group的Owner权限，获取权限后，可以对这个组的runner进行配置，如下图所示：</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/06/3d7c949563ab80e9.png" alt="2023-03-06_101950"></p><h2 id="安装与注册Runner"><a href="#安装与注册Runner" class="headerlink" title="安装与注册Runner"></a>安装与注册Runner</h2><p>可以在runner界面点击“Register a group runner”按钮，再点击红框所示按钮获取安装方法。Docker方式安装的指导链接是<a href="https://docs.gitlab.com/runner/install/docker.html%E3%80%82">https://docs.gitlab.com/runner/install/docker.html。</a></p><p><img src="https://s3.bmp.ovh/imgs/2023/03/06/f777bb20ebc880b3.png" alt="2023-03-06_101713"></p><p>这里我采取了阿里云文档中介绍的安装方法<a href="https://developer.aliyun.com/article/719968%EF%BC%8C%E6%AF%94%E8%BE%83%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%E3%80%82">https://developer.aliyun.com/article/719968，比较通俗易懂。</a></p><h3 id="拉取Runner镜像并启动"><a href="#拉取Runner镜像并启动" class="headerlink" title="拉取Runner镜像并启动"></a>拉取Runner镜像并启动</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name gitlab-runner --restart always -v /srv/gitlab-runner/config:/etc/gitlab-runner -v /var/run/docker.sock:/var/run/docker.sock gitlab/gitlab-runner:latest</span><br></pre></td></tr></table></figure><h3 id="进入Runner容器内"><a href="#进入Runner容器内" class="headerlink" title="进入Runner容器内"></a>进入Runner容器内</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it gitlab-runner bash</span><br></pre></td></tr></table></figure><h3 id="注册Runner"><a href="#注册Runner" class="headerlink" title="注册Runner"></a>注册Runner</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-runner register</span><br></pre></td></tr></table></figure><h4 id="输入Gitlab实例的地址"><a href="#输入Gitlab实例的地址" class="headerlink" title="输入Gitlab实例的地址"></a>输入Gitlab实例的地址</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com )</span><br></pre></td></tr></table></figure><p>这里<strong>注意</strong>不要直接默认，因为默认直接默认的是Gitlab地址<a href="https://gitlab.com,这里需要输入极狐地址https//jihulab.com/%EF%BC%8C%E5%90%A6%E5%88%99%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%BE%93%E5%85%A5%E6%9E%81%E7%8B%90%E7%9A%84token%E5%B0%B1%E4%BC%9A%E4%B8%80%E7%9B%B4%E5%87%BA%E9%94%99">https://gitlab.com，这里需要输入极狐地址https://jihulab.com/，否则下一步输入极狐的token就会一直出错</a>……</p><h4 id="输入token"><a href="#输入token" class="headerlink" title="输入token"></a>输入token</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; Please enter the gitlab-ci token <span class="keyword">for</span> this runner</span><br></pre></td></tr></table></figure><p>复制上图中的“Registration token”输入</p><h4 id="输入Runner的描述"><a href="#输入Runner的描述" class="headerlink" title="输入Runner的描述"></a>输入Runner的描述</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; Please enter the gitlab-ci description <span class="keyword">for</span> this runner</span><br></pre></td></tr></table></figure><p>相当于执行CI&#x2F;CD时显示的runner名称，比如“shuishan test environment runner”</p><h4 id="输入与Runner关联的标签"><a href="#输入与Runner关联的标签" class="headerlink" title="输入与Runner关联的标签"></a>输入与Runner关联的标签</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; Please enter the gitlab-ci tags <span class="keyword">for</span> this runner (comma separated):</span><br></pre></td></tr></table></figure><p>输入相关标签，&#x3D;&#x3D;.gitlab-ci.yml&#x3D;&#x3D;文件会根据标签为选择相应的runner来执行各个Job，比如“shuishan”</p><h4 id="输入Runner的执行器"><a href="#输入Runner的执行器" class="headerlink" title="输入Runner的执行器"></a>输入Runner的执行器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell:</span><br></pre></td></tr></table></figure><p>由于是Docker方式安装，这里输入“docker”</p><h4 id="设置执行器的版本"><a href="#设置执行器的版本" class="headerlink" title="设置执行器的版本"></a>设置执行器的版本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; Please enter the Docker image (eg. ruby:2.1):</span><br></pre></td></tr></table></figure><p>这里选择之前runner的Docker镜像<code>ccchieh/centos-common</code>，如果选择了别的镜像也没关系，后续可以再进行配置</p><h4 id="退出容器"><a href="#退出容器" class="headerlink" title="退出容器"></a>退出容器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><p>执行以上步骤后，就完成了runner的安装与注册，也就可以在runner管理界面看到新的runner了。</p><h2 id="配置Runner"><a href="#配置Runner" class="headerlink" title="配置Runner"></a>配置Runner</h2><p>接下来修改Runner配置文件对runner进行配置，runner配置文件在服务器上的存储位置是<code>/srv/gitlab-runner/config/config.toml</code>，如果有连接终端有可视化文件系统的话就可以直接打开文件对配置进行修改，否则可以使用vim对其进行修改：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /srv/gitlab-runner/config/config.toml</span><br></pre></td></tr></table></figure><p>找到<code>volumes</code>配置，修改为：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumes</span> = [<span class="string">&quot;/cache&quot;</span>,<span class="string">&quot;/var/run/docker.sock:/var/run/docker.sock&quot;</span>,<span class="string">&quot;/data/.m2:/root/.m2&quot;</span>,<span class="string">&quot;/usr/bin/docker:/usr/bin/docker&quot;</span>,<span class="string">&quot;/root/.ssh:/root/.ssh&quot;</span>,<span class="string">&quot;/root/.docker:/root/.docker&quot;</span>]</span><br></pre></td></tr></table></figure><p><code>volumes</code>配置及其作用见下表：</p><table><thead><tr><th>配置</th><th>作用</th></tr></thead><tbody><tr><td>&#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock</td><td>docker daemon监听的套接字socket（ip+port），容器中的进程可以通过它与docker daemon通信</td></tr><tr><td>&#x2F;data&#x2F;.m2:&#x2F;root&#x2F;.m2</td><td>减少拉取Jar包的时间，左边为宿主机目录，右边为容器内的Jar包存储路径.</td></tr><tr><td>&#x2F;usr&#x2F;bin&#x2F;docker:&#x2F;usr&#x2F;bin&#x2F;docker</td><td>使runner在执行作业时可以执行docker命令，否则在执行流水线时会出现以下错误：<img src="https://s3.bmp.ovh/imgs/2023/03/06/5b8322234f098082.png" alt="image-20230306114509472"></td></tr><tr><td>&#x2F;root&#x2F;.ssh:&#x2F;root&#x2F;.ssh</td><td>使runner在执行作业时可以执行ssh命令</td></tr><tr><td>&#x2F;root&#x2F;.docker:&#x2F;root&#x2F;.docker</td><td>使runner在执行作业时可以根据宿主机的docker login信息拉取私有仓库的镜像</td></tr></tbody></table><p>接着在在<code>volumes</code>配置下方增加一行配置，防止Runner重复拉取镜像：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">pull_policy</span> = <span class="string">&quot;if-not-present&quot;</span></span><br></pre></td></tr></table></figure><p>最后重启Runner即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart gitlab-runner</span><br></pre></td></tr></table></figure><p>其余细节(如runners.cache、runners.custom_build_dir)可见以下完整的<code>config.toml</code>文件：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">concurrent</span> = <span class="number">1</span></span><br><span class="line"><span class="attr">check_interval</span> = <span class="number">0</span></span><br><span class="line"><span class="attr">shutdown_timeout</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="section">[session_server]</span></span><br><span class="line">  <span class="attr">session_timeout</span> = <span class="number">1800</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[runners]]</span></span><br><span class="line">  <span class="attr">name</span> = <span class="string">&quot;shuishan test environment&quot;</span></span><br><span class="line">  <span class="attr">url</span> = <span class="string">&quot;https://jihulab.com/&quot;</span></span><br><span class="line">  <span class="attr">id</span> = <span class="number">8150</span></span><br><span class="line">  <span class="attr">token</span> = <span class="string">&quot;xxxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line">  <span class="attr">token_obtained_at</span> = <span class="number">2023</span>-<span class="number">03</span>-<span class="number">01</span>T04:<span class="number">21</span>:<span class="number">56</span>Z</span><br><span class="line">  <span class="attr">token_expires_at</span> = <span class="number">0001</span>-<span class="number">01</span>-<span class="number">01</span>T00:<span class="number">00</span>:<span class="number">00</span>Z</span><br><span class="line">  <span class="attr">executor</span> = <span class="string">&quot;docker&quot;</span></span><br><span class="line">  <span class="section">[runners.custom_build_dir]</span></span><br><span class="line">  <span class="section">[runners.cache]</span></span><br><span class="line">    <span class="section">[runners.cache.s3]</span></span><br><span class="line">    <span class="section">[runners.cache.gcs]</span></span><br><span class="line">    <span class="section">[runners.cache.azure]</span></span><br><span class="line">  <span class="section">[runners.docker]</span></span><br><span class="line">    <span class="attr">tls_verify</span> = <span class="literal">false</span></span><br><span class="line">    <span class="attr">image</span> = <span class="string">&quot;ccchieh/centos-common&quot;</span></span><br><span class="line">    <span class="attr">privileged</span> = <span class="literal">false</span></span><br><span class="line">    <span class="attr">disable_entrypoint_overwrite</span> = <span class="literal">false</span></span><br><span class="line">    <span class="attr">oom_kill_disable</span> = <span class="literal">false</span></span><br><span class="line">    <span class="attr">disable_cache</span> = <span class="literal">false</span></span><br><span class="line">    <span class="attr">volumes</span> = [<span class="string">&quot;/cache&quot;</span>,<span class="string">&quot;/var/run/docker.sock:/var/run/docker.sock&quot;</span>,<span class="string">&quot;/data/.m2:/root/.m2&quot;</span>,<span class="string">&quot;/usr/bin/docker:/usr/bin/docker&quot;</span>,<span class="string">&quot;/root/.ssh:/root/.ssh&quot;</span>,<span class="string">&quot;/root/.docker:/root/.docker&quot;</span>]</span><br><span class="line">    <span class="attr">pull_policy</span> = <span class="string">&quot;if-not-present&quot;</span></span><br><span class="line">    <span class="attr">shm_size</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>gitlab runner容器实现CI&#x2F;CD流水线的原理</strong></p><p>这里执行流水线的操作并不是由<code>gitlab-runner</code>这个容器执行的，每执行一条流水线，<code>gitlab-runner</code>这个容器就会根据<code>config.toml</code>里面配置去重启一个容器，这个容器才是真正的runner，用来执行这条流水线。</p><p>如果运行一条流水线，在服务器上手速快点就可以看到这样的现象，新建了一个容器，等这个流水线跑完，容器就会删除。</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/06/f65c241280db4e30.png" alt="image-20230306133714732"></p><p><code>config.toml</code>里面的<code>volumes</code>挂载，实际上也是从服务器挂载到这个新建的容器里面去的，所以在<code>gitlab-runner</code>这个容器里看不到&#x3D;&#x3D;&#x2F;usr&#x2F;bin&#x2F;docker&#x3D;&#x3D;、&#x3D;&#x3D;&#x2F;root&#x2F;.ssh&#x3D;&#x3D;、&#x3D;&#x3D;&#x2F;root&#x2F;.docker&#x3D;&#x3D;这些文件夹才是对的。要注意这种挂载和容器启动时的<code>docker run -v</code>挂载</p></blockquote><h2 id="服务器的配置"><a href="#服务器的配置" class="headerlink" title="服务器的配置"></a>服务器的配置</h2><p>在服务器上也需要完成一定的配置，使runner在执行一些指令时具有相应的访问权限。</p><h3 id="docker拉取私有镜像权限"><a href="#docker拉取私有镜像权限" class="headerlink" title="docker拉取私有镜像权限"></a>docker拉取私有镜像权限</h3><p>服务器的docker需要登录阿里云私有镜像仓库的账号，使用<code>docker login</code>命令完成登录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login --username=shuishan@1224904496484627 registry.cn-shanghai.aliyuncs.com</span><br></pre></td></tr></table></figure><p>登录完成后会在服务器的<code>/root/.docker/config.json</code>里面保存凭证，在上面的配置中我们已经配置好了这个文件夹的挂载，所以runner就可以在正常执行一些拉取远端私有镜像的操作，否则runner在执行流水线时可能会出现以下报错：</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/06/8ab1366ca700c1d9.png" alt="image-20230306113239187"></p><h3 id="ssh连接测试服务器权限"><a href="#ssh连接测试服务器权限" class="headerlink" title="ssh连接测试服务器权限"></a>ssh连接测试服务器权限</h3><p>在测试环境流水线中需要ssh连接测试服务器完成一些镜像删除、容器部署的操作，所以需要使gitlab-runner容器所在的服务器具有远程ssh连接测试服务器的权限，可以按照如下操作完成配置：</p><h4 id="生成公钥文件"><a href="#生成公钥文件" class="headerlink" title="生成公钥文件"></a>生成公钥文件</h4><p>在runner所在服务器上执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p>程序会问你存放目录，如果不需要修改，直接回车几次即可在<code>~/.ssh</code>目录下生成该主机的公钥文件<code>id_rsa.pub</code>，复制该文件内容。</p><h4 id="导入公钥文件内容"><a href="#导入公钥文件内容" class="headerlink" title="导入公钥文件内容"></a>导入公钥文件内容</h4><p>进入测试服务器的<code>~/.ssh</code>目录，找到<code>authorized_keys</code>文件，往该文件写入上一步复制的公钥文件内容。</p><h4 id="测试ssh连接"><a href="#测试ssh连接" class="headerlink" title="测试ssh连接"></a>测试ssh连接</h4><p>在runner所在服务器上执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh TEST_SERVER_ADDR</span><br></pre></td></tr></table></figure><p><em>TEST_SERVER_ADDR</em>为测试服务器地址，首次连接可能会出现以下信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The authenticity of host <span class="string">&#x27;[host]:12222 ([xxx.xxx.xx.xxx]:12222)&#x27;</span> can<span class="string">&#x27;t be established.</span></span><br><span class="line"><span class="string">ECDSA key fingerprint is SHA256:7g/bojcSbdVWBrfNrQ5+k+XQZuo4mp0V7MnUPD21nec.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)?</span></span><br></pre></td></tr></table></figure><p>这是为了确认是否是我们需要真正连接的服务器 而不是中间人的服务器，直接输入<code>yes</code>即可，这样就会把连接服务器的相关信息写入<code>~/.ssh/known_hosts</code>文件中，之后再连接同一服务器时就不会再出现这个确认信息了。</p><p>在上面的配置中我们已经配置好了<code>~/.ssh</code>这个文件夹的挂载，所以runner就可以在正常执行一些ssh连接测试服务器，否则runner在执行流水线时可能会出现以下报错：</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/06/7e2456df98e50d82.png" alt="image-20230306114445936"></p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>当完成以上操作后，此时流水线已经可以正常执行了，此时可以将所有服务(包括前端和后端，除了超级管理员前后端，那个运行流水线需要相关权限，比较麻烦)中之前失败的或最新一次的流水线重新运行一下，在新的服务器运行第一次流水线，包括构建和部署等操作。因为第一次操作需要下载大量的Maven Jar包，所以构建时间较长，先执行一次流水线不仅可以测试runner是否已经正常，还可以减少后面流水线的运行时间。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;首先需要注意使用&lt;strong&gt;docker&lt;/strong&gt;方式安装runner而不是服务器方式安装runner，这样不仅安装简单，还有利于后续对runner的配置。&lt;/p&gt;
&lt;h2 id=&quot;获取权限&quot;&gt;&lt;a href=&quot;#获取权限&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="Runner" scheme="http://example.com/categories/Runner/"/>
    
    
    <category term="Runner" scheme="http://example.com/tags/Runner/"/>
    
  </entry>
  
</feed>
